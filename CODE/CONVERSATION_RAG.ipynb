{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "43b95876",
      "metadata": {
        "id": "43b95876"
      },
      "source": [
        "# Basic RAG (Retrieval-Augmented Generation) App\n",
        "\n",
        "Upload a PDF, ask questions about its content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6b04e9",
      "metadata": {
        "id": "0f6b04e9"
      },
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "!pip install pypdf faiss-cpu sentence-transformers google-generativeai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "002309c7",
      "metadata": {
        "id": "002309c7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import faiss\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from pypdf import PdfReader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "843491ff",
      "metadata": {
        "id": "843491ff"
      },
      "source": [
        "## 1. Set PDF Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f996a1c2",
      "metadata": {
        "id": "f996a1c2"
      },
      "outputs": [],
      "source": [
        "# Set the path to your PDF file\n",
        "pdf_path = '/content/LoveStories.pdf' # Provide path properly like: ./report.pdf, C:\\\\Users\\\\YOUR_USERNAME\\\\path\\\\project.pdf\n",
        "pdf_file = Path(pdf_path).expanduser()\n",
        "print(f\"Using PDF file: {pdf_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96adec04",
      "metadata": {
        "id": "96adec04"
      },
      "source": [
        "## 2. Extract Text from PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66873ae7",
      "metadata": {
        "id": "66873ae7"
      },
      "outputs": [],
      "source": [
        "reader = PdfReader(pdf_file)\n",
        "all_text = \"\"\n",
        "for page in reader.pages:\n",
        "    all_text += page.extract_text() + \"\\n\"\n",
        "print(f\"Extracted {len(all_text)} characters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c49633f",
      "metadata": {
        "id": "9c49633f"
      },
      "source": [
        "## 3. Chunk Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f89b4b",
      "metadata": {
        "id": "e4f89b4b"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text, chunk_size=500, overlap=100):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        chunk = words[i:i+chunk_size]\n",
        "        chunks.append(' '.join(chunk))\n",
        "        i += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(all_text)\n",
        "print(f\"Total chunks: {len(chunks)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78f42689",
      "metadata": {
        "id": "78f42689"
      },
      "source": [
        "## 4. Embed Chunks and Build Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd4c13d",
      "metadata": {
        "id": "abd4c13d"
      },
      "outputs": [],
      "source": [
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = embedder.encode(chunks, show_progress_bar=True)\n",
        "\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings).astype('float32'))\n",
        "print(f\"FAISS index built with {index.ntotal} vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c947158c",
      "metadata": {
        "id": "c947158c"
      },
      "source": [
        "## 5. Ask Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99bc762a",
      "metadata": {
        "id": "99bc762a"
      },
      "outputs": [],
      "source": [
        "# Google Generative AI API setup\n",
        "genai.configure(api_key=\"YOUR_GOOGLE_API_KEY\")  # Replace with your actual API key\n",
        "\n",
        "# Initialize Gemini model\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "def retrieve(query, k=3):\n",
        "    q_emb = embedder.encode([query])\n",
        "    D, I = index.search(np.array(q_emb).astype('float32'), k)\n",
        "    return [chunks[i] for i in I[0]]\n",
        "\n",
        "# Initialize conversation history outside the function\n",
        "conversation_history = []\n",
        "\n",
        "def rag_answer(query):\n",
        "    # Retrieve relevant context for the current query\n",
        "    context = '\\n'.join(retrieve(query))\n",
        "\n",
        "    # Build the conversation history string\n",
        "    history_str = \"\"\n",
        "    for turn in conversation_history:\n",
        "        history_str += f\"User: {turn['query']}\\nAssistant: {turn['response']}\\n\"\n",
        "\n",
        "    # Build the prompt including the conversation history\n",
        "    prompt = f\"\"\"Use the following context and conversation history to answer the question. Keep your answer concise and relevant.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Conversation History:\n",
        "    {history_str}\n",
        "    User: {query}\n",
        "    Assistant:\"\"\"\n",
        "\n",
        "    # Generate response from the model\n",
        "    response = model.generate_content(prompt)\n",
        "    answer = response.text.strip()\n",
        "\n",
        "    # Update the conversation history\n",
        "    conversation_history.append({'query': query, 'response': answer})\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea345e05",
      "metadata": {
        "id": "ea345e05"
      },
      "source": [
        "## 6. Interactive Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e4da580",
      "metadata": {
        "id": "5e4da580"
      },
      "outputs": [],
      "source": [
        "print(\"Chat with your PDF! Type 'exit' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    query = input(\"You: \")\n",
        "    if query.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    answer = rag_answer(query)\n",
        "    print(f\"Bot: {answer}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Sq2bgGevt0M",
      "metadata": {
        "id": "1Sq2bgGevt0M"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
